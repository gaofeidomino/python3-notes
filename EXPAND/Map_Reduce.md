
# 《MapReduce: Simplified Data Processing on Large Clusters》

* https://research.google/pubs/mapreduce-simplified-data-processing-on-large-clusters/

```
这篇文章介绍了 MapReduce 的概念和在大型集群上的数据处理能力。
MapReduce 是一种用于处理大规模数据集的编程模型和软件框架。
它通过将输入数据集分割成小块，并在分布式计算集群上进行并行处理，最后将结果合并得到最终的输出。
MapReduce 的设计目标是简化大规模数据处理的复杂性，使得开发人员可以更轻松地编写并行化的数据处理程序。
这篇文章详细介绍了 MapReduce 的工作原理、数据流程、任务调度和容错机制等方面。

```

```
    由 Google 的 Jeffrey Dean 和 Sanjay Ghemawat 在 2004 年发表的论文。
    介绍了 MapReduce 框架，这是一种用于处理大规模数据的分布式计算框架。
    
    该框架的核心思想是将数据处理任务分解为两个主要阶段：Map 阶段和 Reduce 阶段。
    
    在 Map 阶段，数据被划分为一系列键值对，并由多个分布式节点并行处理，生成中间结果。
    
    在 Reduce 阶段，相同键的中间结果被合并并进行汇总处理。
    
    MapReduce 框架简化了大规模数据处理的流程，并提供了容错性和可伸缩性，使得开发者可以更轻松地编写并行化的数据处理程序。

```


# 详情

```
Map 阶段：
    在 Map 阶段，输入数据集被划分为若干个逻辑片段，并由多个并行运行的 Map 任务处理。每个 Map 任务将输入数据转换为一系列中间键值对。
    中间键值对的生成过程由用户编写的 Map 函数定义。这个函数独立地对每个输入片段进行处理，并将其转换为中间键值对。
    中间键值对的键和值由用户指定，可以是任意类型的数据。

Shuffle 阶段：
    在 Map 阶段完成后，MapReduce 框架会对中间键值对进行排序和分区，以便将相同键的数据发送到相同的 Reduce 任务进行处理。
    这个阶段的核心任务是数据的分发和排序，以便将相关数据传递给 Reduce 任务。

Reduce 阶段：
    Reduce 阶段的输入是分组后的中间键值对，每个 Reduce 任务独立处理一组键值对。
    用户编写的 Reduce 函数定义了如何对具有相同键的键值对进行合并和汇总。
    每个 Reduce 任务输出最终的处理结果，将它们写入到输出数据集中。

MapReduce 框架提供了自动化的并行化、容错性和负载平衡，使得用户可以专注于问题的逻辑而无需关注底层的分布式细节。该框架的设计简单而灵活，适用于大规模数据处理应用，并已被广泛应用于各种领域的数据处理任务中。

```